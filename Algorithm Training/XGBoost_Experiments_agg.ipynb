{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fec605",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter tuning\n",
    "\n",
    "best_auc=0\n",
    "best_param={0,0,0,0,0,0}\n",
    "all_auc=[]\n",
    "all_param=[]\n",
    "best_aucpr=0\n",
    "all_aucpr=[]\n",
    "best_parampr={0,0,0,0,0,0}\n",
    "time=[]\n",
    "confusion=[]\n",
    "\n",
    "start=datetime.now()\n",
    "\n",
    "for i in range(16):\n",
    "     for k in range(20):\n",
    "        \n",
    "        print('run ' + str(i) + '.' + str(k) + ' started at ' + str(datetime.now()))\n",
    "        np.random.seed(i)\n",
    "        train_df_split = train_df_ready.reindex(np.random.permutation(train_df_ready.index))\n",
    "        val_ids = list(train_df_split['EC batch'].unique())[-int(val_ratio*len(train_df_split['EC batch'].unique())):]\n",
    "        val_df_pre = train_df_ready[train_df_ready['EC batch'].isin(val_ids)]\n",
    "        train_df_pre = train_df_ready[~train_df_ready['EC batch'].isin(val_ids)]\n",
    "        \n",
    "        del train_df_split\n",
    "\n",
    "        n_estimators = np.random.randint(150, 1000)\n",
    "        learning_rate = np.random.uniform(0.01, 0.07)\n",
    "        subsample = np.random.uniform(0.1, 1)\n",
    "        max_depth = np.random.randint(3, 9)\n",
    "        colsample_bytree = np.random.uniform(0.1, 1)\n",
    "        min_child_weight = np.random.randint(1, 4)\n",
    "        params_str = \"_\".join([str(n_estimators), str(learning_rate), str(subsample), str(max_depth), \n",
    "                               str(colsample_bytree), str(min_child_weight)])\n",
    "\n",
    "\n",
    "        X_train = train_df_pre.drop(['Adherence','Effective Dating','unique_id','unique_id_event','create_timestamp','EC batch'],axis=1)\n",
    "        y_train = train_df_pre['Adherence']\n",
    "        X_val = val_df_pre.drop(['Adherence','Effective Dating','unique_id','unique_id_event','create_timestamp','EC batch'],axis=1)\n",
    "        y_val = val_df_pre['Adherence']\n",
    "        class_ratio=(y_train.value_counts()[0]/y_train.value_counts()[1])\n",
    "        \n",
    "        del train_df_pre,val_df_pre\n",
    "\n",
    "#         class_ratio=9\n",
    "        \n",
    "        xgb_model= xgb.XGBClassifier(objective='binary:logistic',n_estimators=n_estimators,learning_rate=learning_rate,subsample=subsample,\n",
    "                                    max_depth=max_depth,colsample_bytree=colsample_bytree,min_child_weight=min_child_weight,eval_metric='auc',\n",
    "                                    use_label_encoder=False,random_state=(i+1)*(k+1), scale_pos_weight=class_ratio, tree_method='hist')\n",
    "\n",
    "#         print(datetime.now())\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "#         print(datetime.now())\n",
    "        ns_probs = [0 for _ in range(len(y_val))]\n",
    "\n",
    "        lr_probs = xgb_model.predict_proba(X_val)\n",
    "        # keep probabilities for the positive outcome only\n",
    "        lr_probs = lr_probs[:, 1]\n",
    "        \n",
    "        # calculate the precision-recall auc\n",
    "        precision, recall, _ = precision_recall_curve(y_val, lr_probs)\n",
    "        pr_auc = auc(recall, precision)\n",
    "#         print(pr_auc)\n",
    "        \n",
    "        # calculate scores\n",
    "        ns_auc = roc_auc_score(y_val, ns_probs)\n",
    "        lr_auc = roc_auc_score(y_val, lr_probs)\n",
    "        # summarize scores\n",
    "#         print(lr_auc)\n",
    "        predictions = xgb_model.predict(X_val)\n",
    "#         print(classification_report(y_val,predictions))\n",
    "        \n",
    "        confusion.append(precision_recall_fscore_support(y_val, predictions, average=None))\n",
    "        confusion.append(precision_recall_fscore_support(y_val, predictions, average='macro'))\n",
    "        confusion.append(precision_recall_fscore_support(y_val, predictions, average='weighted'))\n",
    "        \n",
    "        if lr_auc>best_auc:\n",
    "            best_auc=lr_auc\n",
    "            best_param={'run ' +str(i)+'.'+str(k), 'n_estimatmors' +str(n_estimators), 'lr' + str(learning_rate),\n",
    "                        'ss' + str(subsample), 'md' + str(max_depth) , 'cs' + str(colsample_bytree) , 'mcw' + str(min_child_weight)}\n",
    "        \n",
    "        if pr_auc>best_aucpr:\n",
    "            best_aucpr=pr_auc\n",
    "            best_parampr={'run ' +str(i)+'.'+str(k), 'n_estimatmors' +str(n_estimators), 'lr' + str(learning_rate),\n",
    "                        'ss' + str(subsample), 'md' + str(max_depth) , 'cs' + str(colsample_bytree) , 'mcw' + str(min_child_weight)}\n",
    "\n",
    "        all_auc.append(lr_auc)\n",
    "        all_aucpr.append(pr_auc)\n",
    "        all_param.append(['n_estimators= ' +str(n_estimators),'learning_rate= ' +str(learning_rate),\n",
    "                          'subsample= ' +str(subsample), 'max_depth= ' +str(max_depth), 'colsample_bytree= ' +str(colsample_bytree),\n",
    "                          'min_child_weight= ' +str(min_child_weight)])\n",
    "        \n",
    "        \n",
    "        print(pr_auc)\n",
    "        print(lr_auc)\n",
    "        print('run ' + str(i)  + '.' + str(k) + ' ended at ' + str(datetime.now()))\n",
    "        \n",
    "print('cv ended at ' + str(datetime.now()))\n",
    "\n",
    "end=datetime.now()\n",
    "time.append(end-start)\n",
    "\n",
    "fileexport_confusion='Data/confusion_xgb_agg.csv'\n",
    "fileexport_time='Data/time_xgb_agg.csv'\n",
    "fileexport_bestauc='Data/best_auc_xgb_agg.csv'\n",
    "fileexport_bestparam='Data/best_param_xgb_agg.csv'\n",
    "fileexport_bestaucpr='Data/best_aucpr_xgb_agg.csv'\n",
    "fileexport_bestparampr='Data/best_parampr_xgb_agg.csv'\n",
    "fileexport_auc='Data/all_auc_xgb_agg.csv'\n",
    "fileexport_aucpr='Data/all_aucpr_xgb_agg.csv'\n",
    "fileexport_param='Data/all_param_xgb_agg.csv'\n",
    "pd.DataFrame(best_param).to_csv(fileexport_bestparam,index=False, header=False)\n",
    "pd.DataFrame(best_parampr).to_csv(fileexport_bestparampr,index=False, header=False)\n",
    "pd.DataFrame(all_auc).to_csv(fileexport_auc,index=False, header=False)\n",
    "pd.DataFrame(all_aucpr).to_csv(fileexport_aucpr,index=False, header=False)\n",
    "pd.DataFrame(all_param).to_csv(fileexport_param,index=False, header=False)\n",
    "pd.DataFrame(time).to_csv(fileexport_time,index=False, header=False)\n",
    "pd.DataFrame(confusion).to_csv(fileexport_confusion, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae4ba6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_auc=0\n",
    "best_param={0,0,0,0,0,0}\n",
    "all_auc=[]\n",
    "all_param=[]\n",
    "best_aucpr=0\n",
    "all_aucpr=[]\n",
    "best_parampr={0,0,0,0,0,0}\n",
    "time=[]\n",
    "confusion=[]\n",
    "\n",
    "start=datetime.now()\n",
    "\n",
    "for i in range(16):\n",
    "     for k in range(20):\n",
    "        \n",
    "        print('run ' + str(i) + '.' + str(k) + ' started at ' + str(datetime.now()))\n",
    "        np.random.seed(i)\n",
    "        train_df_split = train_df_ready.reindex(np.random.permutation(train_df_ready.index))\n",
    "        val_ids = list(train_df_split['EC batch'].unique())[-int(val_ratio*len(train_df_split['EC batch'].unique())):]\n",
    "        val_df_pre = train_df_ready[train_df_ready['EC batch'].isin(val_ids)]\n",
    "        train_df_pre = train_df_ready[~train_df_ready['EC batch'].isin(val_ids)]\n",
    "        \n",
    "        del train_df_split\n",
    "\n",
    "        n_estimators = np.random.randint(150, 1000)\n",
    "        learning_rate = np.random.uniform(0.01, 0.07)\n",
    "        subsample = np.random.uniform(0.1, 1)\n",
    "        max_depth = np.random.randint(3, 9)\n",
    "        colsample_bytree = np.random.uniform(0.1, 1)\n",
    "        min_child_weight = np.random.randint(1, 4)\n",
    "        params_str = \"_\".join([str(n_estimators), str(learning_rate), str(subsample), str(max_depth), \n",
    "                               str(colsample_bytree), str(min_child_weight)])\n",
    "\n",
    "\n",
    "        X_train = train_df_pre.drop(['Adherence','Effective Dating','unique_id','unique_id_event','create_timestamp','EC batch'],axis=1)\n",
    "        y_train = train_df_pre['Adherence']\n",
    "        X_val = val_df_pre.drop(['Adherence','Effective Dating','unique_id','unique_id_event','create_timestamp','EC batch'],axis=1)\n",
    "        y_val = val_df_pre['Adherence']\n",
    "        class_ratio=(y_train.value_counts()[0]/y_train.value_counts()[1])\n",
    "        \n",
    "        del train_df_pre,val_df_pre\n",
    "\n",
    "#         class_ratio=9\n",
    "        \n",
    "        xgb_model= xgb.XGBClassifier(objective='binary:logistic',n_estimators=n_estimators,learning_rate=learning_rate,subsample=subsample,\n",
    "                                    max_depth=max_depth,colsample_bytree=colsample_bytree,min_child_weight=min_child_weight,eval_metric='auc',\n",
    "                                    use_label_encoder=False,random_state=(i+1)*(k+1), scale_pos_weight=class_ratio, tree_method='hist')\n",
    "\n",
    "#         print(datetime.now())\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "#         print(datetime.now())\n",
    "        ns_probs = [0 for _ in range(len(y_val))]\n",
    "\n",
    "        lr_probs = xgb_model.predict_proba(X_val)\n",
    "        # keep probabilities for the positive outcome only\n",
    "        lr_probs = lr_probs[:, 1]\n",
    "        \n",
    "        # calculate the precision-recall auc\n",
    "        precision, recall, _ = precision_recall_curve(y_val, lr_probs)\n",
    "        pr_auc = auc(recall, precision)\n",
    "#         print(pr_auc)\n",
    "        \n",
    "        # calculate scores\n",
    "        ns_auc = roc_auc_score(y_val, ns_probs)\n",
    "        lr_auc = roc_auc_score(y_val, lr_probs)\n",
    "        # summarize scores\n",
    "#         print(lr_auc)\n",
    "        predictions = xgb_model.predict(X_val)\n",
    "#         print(classification_report(y_val,predictions))\n",
    "        \n",
    "        confusion.append(precision_recall_fscore_support(y_val, predictions, average=None))\n",
    "        confusion.append(precision_recall_fscore_support(y_val, predictions, average='macro'))\n",
    "        confusion.append(precision_recall_fscore_support(y_val, predictions, average='weighted'))\n",
    "        \n",
    "        if lr_auc>best_auc:\n",
    "            best_auc=lr_auc\n",
    "            best_param={'run ' +str(i)+'.'+str(k), 'n_estimatmors' +str(n_estimators), 'lr' + str(learning_rate),\n",
    "                        'ss' + str(subsample), 'md' + str(max_depth) , 'cs' + str(colsample_bytree) , 'mcw' + str(min_child_weight)}\n",
    "        \n",
    "        if pr_auc>best_aucpr:\n",
    "            best_aucpr=pr_auc\n",
    "            best_parampr={'run ' +str(i)+'.'+str(k), 'n_estimatmors' +str(n_estimators), 'lr' + str(learning_rate),\n",
    "                        'ss' + str(subsample), 'md' + str(max_depth) , 'cs' + str(colsample_bytree) , 'mcw' + str(min_child_weight)}\n",
    "\n",
    "        all_auc.append(lr_auc)\n",
    "        all_aucpr.append(pr_auc)\n",
    "        all_param.append(['n_estimators= ' +str(n_estimators),'learning_rate= ' +str(learning_rate),\n",
    "                          'subsample= ' +str(subsample), 'max_depth= ' +str(max_depth), 'colsample_bytree= ' +str(colsample_bytree),\n",
    "                          'min_child_weight= ' +str(min_child_weight)])\n",
    "        \n",
    "        \n",
    "        print(pr_auc)\n",
    "        print(lr_auc)\n",
    "        print('run ' + str(i)  + '.' + str(k) + ' ended at ' + str(datetime.now()))\n",
    "        \n",
    "print('cv ended at ' + str(datetime.now()))\n",
    "\n",
    "end=datetime.now()\n",
    "time.append(end-start)\n",
    "\n",
    "fileexport_confusion='Data/confusion_xgb_agg_pca.csv'\n",
    "fileexport_time='Data/time_xgb_agg_pca.csv'\n",
    "fileexport_bestauc='Data/best_auc_xgb_agg_pca.csv'\n",
    "fileexport_bestparam='Data/best_param_xgb_agg_pca.csv'\n",
    "fileexport_bestaucpr='Data/best_aucpr_xgb_agg_pca.csv'\n",
    "fileexport_bestparampr='Data/best_parampr_xgb_agg_pca.csv'\n",
    "fileexport_auc='Data/all_auc_xgb_agg_pca.csv'\n",
    "fileexport_aucpr='Data/all_aucpr_xgb_agg_pca.csv'\n",
    "fileexport_param='Data/all_param_xgb_agg_pca.csv'\n",
    "pd.DataFrame(best_param).to_csv(fileexport_bestparam,index=False, header=False)\n",
    "pd.DataFrame(best_parampr).to_csv(fileexport_bestparampr,index=False, header=False)\n",
    "pd.DataFrame(all_auc).to_csv(fileexport_auc,index=False, header=False)\n",
    "pd.DataFrame(all_aucpr).to_csv(fileexport_aucpr,index=False, header=False)\n",
    "pd.DataFrame(all_param).to_csv(fileexport_param,index=False, header=False)\n",
    "pd.DataFrame(time).to_csv(fileexport_time,index=False, header=False)\n",
    "pd.DataFrame(confusion).to_csv(fileexport_confusion, index=False, header=False)\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
